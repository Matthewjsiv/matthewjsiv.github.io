---
title: Summary of Current Research
tags: Research
type: article
cover: /assets/media/summary.png
show_date: false
show_edit_on_github: false
show_tags: false
footer: false
permalink: /projects/summary.html
show_subscribe: false
license: false
excerpt: "<ul> <li>High-level summary of my current research in autonomous off-road driving and high-speed racing</li><ul>"
article_header:
  type: cover
  <!-- image:
    src: /assets/media/summary.png -->
---

<!-- *  Perception and high-level control system for drone to detect, track, and follow a person with onboard camera) -->
<!-- *  Uses Google's Posenet and hand-designed subject-visibility metrics -->

<!-- <p> preview excerpt </p> -->
<!-- - Bullet -->

<!--more-->

# Autonomous Off-Road Driving
**I will continue to update this as I develop more cohesive results and figures**

My research for my Master's thesis centers around the following concepts under the context of off-road driving:
- **Self-supervised learning** - leveraging cues intrinsic to collected data (e.g. expert demonstration, proprioceptive cues) rather than expensive manual labels
- **Online adaptation** - designing an autonomous system that can adapt its behavior as it experiences previously-unseen terrain
- **Multi-modal representation learning** - using different sensors simultaneously to perceive geometric, semantic, and other information in the environment

Recently, I've been exploring how to use generalized features from visual foundation models to influence adaptive behaviors. The strong feature extractors allow us to perform terrain segmentation and uncertainty detection without labelling any of our own data. Coupling this with proprioceptive information such as IMU data allows us to quickly learn about the difficulty/roughness of terrain we haven't seen before.


<figure>
<img src="/assets/media/summary/segmentation.png" alt="Overview flowchart" style="width: 70%; display: block; margin-left: auto; margin-right: auto" />  
<figcaption style="text-align: center"> Following an approach inspired by <a target="https://anyloc.github.io/" href="link_here">AnyLoc</a>, we can obtain rough terrain segmentation without any labels. Additionally, we can detect areas of uncertainty (for example the circled puddle that has not been assigned a color). </figcaption>
</figure>


<figure>
<img src="/assets/media/summary/speed.png" alt="Overview flowchart" style="width: 70%; display: block; margin-left: auto; margin-right: auto" />  
<figcaption style="text-align: center">In real-time we can learn what speeds are appropriate for different types of terrain. Lighter areas correspond to faster speeds.</figcaption>
</figure>

# Autonomous High-Speed Racing

I've been a member of the MIT-PITT-RW racing team since 2020, where I've been working on perception algorithms and serving as a mentor to younger students.

One effort I've been working on recently is reducing the number of manual labels needed to train our object detection networks. I've set up a pipeline that uses the few manual labels that we have to generate a "bank" of example pointclouds of the enemy car at different ranges. We then use the GPS information from the other car (we have access to other teams' data post-race) to act as a guess to initializ ICP between cars in the car bank and a new unlabeled pointcloud. The result is an automatic labelling pipeline.

<figure>
<img src="/assets/media/summary/extract.png" alt="Overview flowchart" style="width: 70%; display: block; margin-left: auto; margin-right: auto" />  
<figcaption style="text-align: center">Using the known location of the car from hand labels, we generate a bank of car point clouds.</figcaption>
</figure>

<figure>
<img src="/assets/media/summary/refine.png" alt="Overview flowchart" style="width: 70%; display: block; margin-left: auto; margin-right: auto" />  
<figcaption style="text-align: center">We use gps information from the other car to initialize ICP to get accurate labels automatically.</figcaption>
</figure>



<!-- Labeled data for off-road terrain is scarce, and acquiring more is expensive, so our group maintains a heavy emphasis on algorithms that don't require any manual labeling and instead leverage cues that are already present in the collected data, such as expert demonstrations or proprioceptive information. Additionally, off-road terrain is extremely diverse. While our testing site is expansive, any other area that we test in will be significantly different -->
